{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型的训练\n",
    "分类问题是有监督学习问题的一种，简单来说就是根据数据的特征将其划分到某个已经存在的类别中。分类问题主要有两个过程:\n",
    "1. 学习: 根据训练集中的样本，学习样本特征到类别标签的映射(分类器).\n",
    "2. 分类: 根据学习得到的分类器，对新样本进行预测，结果可以是确定的类别也可以是每个类别的概率\n",
    "\n",
    "\n",
    "## 1. Logistic Regression\n",
    "\n",
    "逻辑回归看名字是个回归算法，其实是个分类算法，它是 SoftMax 的一个简化版本，适用于二分类问题。\n",
    "\n",
    "logistic的模型为如下的条件概率分布:\n",
    "\n",
    "$$ P(Y=1|x) = \\frac{1}{1+\\exp(w^{T}x)} $$\n",
    "$$ P(Y=0|x) = \\frac{\\exp(w^{T}x)}{1+\\exp(w^{T}x)} $$\n",
    "> 注意：y=0和y=1的两个概率表达式可以互换，结果就是学习出来的参数w不同罢了，总之，模型都会表现出样本的特点。\n",
    "\n",
    "由于$Y$的取值为{0,1}，所以其服从二项分布，设 $h_{w}(x) = P(Y=1|x)$,则有:\n",
    "\n",
    "$$ P(y|x; w) = h_{w}(x)^{y} + (1-h_{w}(x))^{1-y} $$\n",
    "利用最大似然估计来求解参数$w$, 对数似然函数为:\n",
    "\n",
    "$$ l(w) = \\sum_{i=1}^{N} y^{i}\\log h_{w}(x^{i}) + (1-y^{i})\\log (1-h_{w}(x^{i}))$$\n",
    "Logistic回归的损失函数通常是负的对数似然函数，把问题转换为求最小值的问题:\n",
    "\n",
    "$$ L(y^{i}, \\hat y^{i}) = -l(w), y^{i} \\in {0, 1} $$\n",
    "$$ L(y^{i}, \\hat y^{i}) = -\\sum_{i=1}^{N} log(1 + \\exp(y^{i}*(x^{i} \\odot w))), y^{i} \\in {-1, 1} $$\n",
    "所要求解的目标是:\n",
    "\n",
    "$$ min_{w} L(y^{i}, \\hat y^{i})$$\n",
    "使用梯度下降算法求解即可。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
