{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 在 MNIST 中的应用\n",
    "接下来会使用，softmax, cnn, rnn以及自编码器的方式来在MNIST数据集上训练模型，来更好的上手tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoftMax 分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./datasets/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# 1.加载数据\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# flags = tf.app.flags\n",
    "# FLAGS = flags.FLAGS\n",
    "# flags.DEFINE_string('data_dir', './datasets/mnist/', 'Directory for storing data')\n",
    "mnist = input_data.read_data_sets(\"./datasets/mnist/\", one_hot=True)\n",
    "\n",
    "# 使用one_hot 的直接原因是，我们使用0～9 个类别的多分类的输出层是softmax 层，它的输\n",
    "# 出是一个概率分布，从而要求输入的标记也以概率分布的形式出现，进而可以计算交叉熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.构造模型（定义计算图）\n",
    "\n",
    "# 定义输入数据的占位符\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 定义参数\n",
    "w = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# 定义模型\n",
    "y_pred = tf.matmul(x, w) + b\n",
    "\n",
    "# 定义损失函数(交叉熵损失函数)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=y, logits=y_pred)) #在这个函数里进行softmax\n",
    "# 定义优化器\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.训练模型\n",
    "\n",
    "# 全局初始化器\n",
    "init = tf.global_variables_initializer()\n",
    "# 创建交互式上下文的TensorFlow 会话 ,与常规会话不同的是，交互式会话会成为默认会话\n",
    "sess = tf.InteractiveSession()\n",
    "#with tf.Session() as sess:\n",
    "sess.run(init)\n",
    "\n",
    "# 迭代1000次，batchsize=128\n",
    "for _ in range(1000):\n",
    "    batch_x, batch_y = mnist.train.next_batch(128)\n",
    "    sess.run(train_step, feed_dict={x: batch_x, y: batch_y})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9208\n"
     ]
    }
   ],
   "source": [
    "# 4.评估模型\n",
    "\n",
    "# 由于使用了 onehot编码，label从一维变为了十维,tf.argmax(y,1)返回的是模型对任一输入 x 预测到的标记值，\n",
    "# tf.argmax(y_,1)代表正确的标记值。我们用 tf.equal 来检测预测值和真实值是否匹配，\n",
    "# 并且将预测后得到的布尔值转化成浮点数，并取平均值\n",
    "\n",
    "# 评估训练好的模型\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_pred, 1)) # 类似 y==y_pred,每行比较\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # sum(y,y_pred,axis=0)/len(y)\n",
    "\n",
    "# 计算模型在测试集上的准确率 \n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-314da8e5d4af>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./datasets/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./datasets/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# 1. 导入库， 载数据\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "mnist = input_data.read_data_sets('./datasets/mnist/', one_hot=True)\n",
    "# 划分训练集和测试集\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n",
    "# 转化为4维\n",
    "trX, teX = list(map(lambda x: x.reshape([-1, 28, 28, 1]), [trX, teX]))\n",
    "#print(trX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-5f91a443047d>:42: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.构造模型，计算图\n",
    "# 网络结构: 3 个卷积层和3 个池化层 1 个全连接层和 1 个输出层\n",
    "# 输入数据的占位符\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 定义权重\n",
    "# 卷积核大小均为 3*3\n",
    "w1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=.01), name='w1') # 32个卷积核\n",
    "w2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=.01), name='w2') # 64个卷积核\n",
    "w3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=.01), name='w3') # 128个卷积核\n",
    "w4 = tf.Variable(tf.random_normal([128*4*4, 625], stddev=.01), name='w4') # 全连接层， 输入维度为 128 × 4 × 4,是上一层的输出数据又三维的转变成一维\n",
    "wo = tf.Variable(tf.random_normal([625, 10], stddev=.01), name='wo') # 输出层，输出维度10代表结果为10个类别\n",
    "# dropout\n",
    "prob_keep_conv, prob_keep_full= 0.8, 0.5\n",
    "# 定义网络结构\n",
    "# conv1\n",
    "l1 = tf.nn.conv2d(x, w1, strides=[1,1,1,1], padding='SAME')#shape=(?, 28, 28, 32) \n",
    "l1 = tf.nn.relu(l1)\n",
    "l1 = tf.nn.max_pool(l1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') # shape=(?, 14, 14, 32) \n",
    "l1 = tf.nn.dropout(l1, prob_keep_conv)\n",
    "# conv2\n",
    "l2 = tf.nn.conv2d(l1, w2, strides=[1,1,1,1], padding='SAME') # shape=(?, 14, 14, 64) \n",
    "l2 = tf.nn.relu(l2)\n",
    "l2 = tf.nn.max_pool(l2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') # shape=(?, 7, 7, 64) \n",
    "l2 = tf.nn.dropout(l2, prob_keep_conv)\n",
    "# conv3\n",
    "l3 = tf.nn.conv2d(l2, w3, strides=[1,1,1,1], padding='SAME') # shape=(?, 7, 7, 128) \n",
    "l3 = tf.nn.relu(l3)\n",
    "l3 = tf.nn.max_pool(l3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') # shape=(?, 4, 4, 128) \n",
    "l3 = tf.reshape(l3, [-1, w4.get_shape().as_list()[0]]) # reshape to (? 2048)\n",
    "l3 = tf.nn.dropout(l3, prob_keep_conv)\n",
    "# full connection 1\n",
    "l4 = tf.matmul(l3, w4)\n",
    "l4 = tf.nn.relu(l4)\n",
    "l4 = tf.nn.dropout(l4, prob_keep_full)\n",
    "# 输出层\n",
    "out = tf.matmul(l4, wo) \n",
    "# 注意：最后一层现在没有使用softmax，到计算损失函数的时候在使用,其实预测类别时无须使用softmax，值最大的经过softmax还是最大，求概率和交叉熵时使用\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=out))\n",
    "train_opt = tf.train.RMSPropOptimizer(learning_rate=.001, decay=.9).minimize(cost) # 学习率为0.001，衰减值为 0.9\n",
    "\n",
    "predict_cls = tf.argmax(out, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28, 1)\n",
      "batch: 0, cost: 2.302584171295166\n",
      "batch: 1, cost: 2.3025898933410645\n",
      "batch: 2, cost: 2.3025877475738525\n",
      "batch: 3, cost: 2.302583932876587\n",
      "batch: 4, cost: 2.302582025527954\n"
     ]
    }
   ],
   "source": [
    "# 训练模型 和 评估模型\n",
    "#print(trX.shape)\n",
    "def get_next_batch(x, y, batch_size):\n",
    "    print(x.shape)\n",
    "    shuffle_train_indices = np.arange(len(trX))\n",
    "    np.random.shuffle(shuffle_train_indices)\n",
    "    x, y = x[shuffle_train_indices], y[shuffle_train_indices]\n",
    "    batch_nums = len(x) // batch_size\n",
    "    for i in range(0, batch_nums):\n",
    "        yield x[i:(i+1)*batch_size], y[i:(i+1)*batch_size]\n",
    "    now_ = batch_nums * batch_size \n",
    "    if now_ < len(x):\n",
    "        yield x[now_:], y[now_:]\n",
    "\n",
    "batch_size = 128\n",
    "test_size = 256\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run() # 全局Variable 初始化\n",
    "    for i in range(10):\n",
    "        batch = 0\n",
    "        for batch_x, batch_y in get_next_batch(trX, trY, batch_size):\n",
    "            sess.run(train_opt, feed_dict={x: batch_x, y: batch_y})\n",
    "            print(\"batch: {}, cost: {}\".format(batch, sess.run(cost, feed_dict={x: batch_x, y: batch_y})))\n",
    "            batch += 1\n",
    "        #print(\"iters: {}, cost: {}\".format(i+1, sess.run(cost, feed_dict={x: trX, y: trY})))\n",
    "            \n",
    "    # 评估模型\n",
    "    correct_prediction = tf.reduce_sum(tf.argmax(y, 1), predict_cls)\n",
    "    accuracy = correct_prediction / len(x)\n",
    "    print(sess.run(accuracy, feed_dict={x: teX, y: teY}))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-ef73a4b633c5>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./datasets/mnist\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./datasets/mnist\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./datasets/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./datasets/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# 1. 加载数据 导入库\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('./datasets/mnist', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.构建模型\n",
    "\n",
    "# 设置超参数\n",
    "lr = .001 # 学习率\n",
    "train_iters = 10000 # 迭代次数\n",
    "batch_size = 128 # mini_batch\n",
    "\n",
    "# 设置网络参数\n",
    "# 为了使用 RNN 来分类图片，把每张图片的行看成是一个像素序列\n",
    "# 每一步输入的序列长度是28，输入的步数是28 步\n",
    "n_inputs = 28\n",
    "n_steps = 28\n",
    "n_hidden_units = 128 # 隐层神经元的个数\n",
    "n_classes = 10\n",
    "\n",
    "# 输入数据的占位符\n",
    "x = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 定义初始权重, rnn中参数共享\n",
    "weights = {\n",
    "    'in': tf.Variable(tf.random_normal([n_inputs, n_hidden_units])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_units, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'in': tf.Variable(tf.constant(0.1, shape=[n_hidden_units, ])), \n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[n_classes, ]))\n",
    "}\n",
    "\n",
    "# 定义RNN模型\n",
    "def RNN(x, weights, biases):\n",
    "    # X ==> (128 batch * 28 steps, 28 inputs)\n",
    "    X = tf.reshape(x, [-1, n_inputs])\n",
    "    \n",
    "    # 进入隐藏层\n",
    "    X_in = tf.matmul(X, weights['in']) + biases['in'] # X_in > [128 batch*28 steps, 128 hidden_units]\n",
    "    # X_in > [128 batch, 28 step, 128 hidden unit]\n",
    "    X_in = tf.reshape(X_in, [-1, n_steps, n_hidden_units])\n",
    "    \n",
    "    # 基本的LSTM 循环网络单元\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden_units, forget_bias=1.0, state_is_tuple=True)\n",
    "    # 初始化为零值，lstm单元由两个部分组成：(c_state, h_state)\n",
    "    init_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "    # dynamic_rnn 接收输入张量(batch, steps, inputs)\n",
    "    outputs, final_states = tf.nn.dynamic_rnn(lstm_cell, X_in, initial_state=init_state, time_major=False)\n",
    "    \n",
    "    results = tf.matmul(final_states[1], weights['out']) + biases['out']\n",
    "    return results\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "y_pred = RNN(x, weights, biases)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_pred)) # 先softmax 后交叉熵\n",
    "train_optimizer = tf.train.AdamOptimizer(lr).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练和评估模型\n",
    "correct_prediction = tf.reduce_sum(tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1)))\n",
    "accuracy = correct_prediction / len(y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    step = 0\n",
    "    while step*batch_size < n_iters:\n",
    "        batch_X, batch_y = mnist.train.next_batch(batch_size)\n",
    "        batch_X = tf.reshape(batch_X, [batch_size, n_steps, n_inputs])\n",
    "        sess.run(train_opt, feed_dict={x: batch_X, y: batch_y})\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            now_loss = sess.run(cost, feed_dict={x: batch_X, y: batch_y})\n",
    "            print(now_loss)\n",
    "        step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
