{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础\n",
    "\n",
    "## 1.什么是机器学习？\n",
    "\n",
    "机器学习就是让机器从数据中自动获取有用的函数，例如对于分类而言，要找的就是从特征到标签的映射函数；对回归而言就是找到特征与连续值的函数关系。\n",
    "\n",
    "既然机器学习就是找出一个好的函数，那么肯定要告诉机器从哪里找，也要告诉机器什么是好函数让它有个目标，同时也要告诉机器怎么去找，这就引出了机器学习的三要素。\n",
    "\n",
    "## 2.机器学习三要素\n",
    "\n",
    "* 模型：也称为假设空间，告诉机器从哪里找函数\n",
    "* 策略：定义 按照什么的准则来选择或学习最优的模型，也即定义什么是好函数\n",
    "* 算法：怎样去求解好函数也即最优的模型\n",
    "\n",
    "### 2.1 模型\n",
    "\n",
    "模型的假设空间： 以监督学习为例，模型的假设空间包含所有可能的条件概率分布或决策函数(非概率)。例如，假设决策函数是线性函数那么模型的假设空间就是所有的线性函数所构成的函数集合。假设空间通常是由参数向量构成的函数族。\n",
    "* 决策函数:\n",
    "\n",
    "    $$ F = \\{f | y = f_{\\vec \\theta}(\\vec x)\\} $$\n",
    "  其中 $\\vec \\theta$是参数向量，取值于n维欧式空间$R^{n}$，成为参数空间。\n",
    "* 条件概率分布:\n",
    "    $$ F = \\{P | P_{\\theta}(Y|X)\\} $$\n",
    "\n",
    "### 2.2 策略\n",
    "学习的目标在于从假设空间中找出最优模型， 定义 损失函数用来衡量一次模型预测的好坏，风险函数度量平均模型预测的好坏。\n",
    "#### 2.2.1 损失函数\n",
    "假设选取一个模型$f$， 则其预测的输出值 $f(X)$可能与真是值$Y$ 不同，用损失函数或者代价函数来度量预测错误的程度，损失函数是 $f(x)$ 与 $Y$的非负值函数，记作 $L(f(x), Y)$.\n",
    "常用的损失函数主要有:\n",
    "\n",
    "* 平方损失 :\n",
    "    $$ L(f(x), Y) = (Y - f(x))^{2} $$\n",
    "* 对数损失:\n",
    "    $$ L(f(x), Y) = -\\log (P(Y | X)) $$\n",
    "* 交叉熵损失:\n",
    "    $$ L(p, q) = -\\sum_{x}{p(x) \\log q(x)} $$\n",
    "  p为数据真实分布，q为预测分布，交叉熵损失函数可以用来衡量p和q之间的相似度,也能避免使用sigmoid函数在梯度下降时能均方误差损失函数学习速率降低的问题，因为学习速率可以被输出的误差所控制.\n",
    "\n",
    "#### 2.2.2 风险函数\n",
    "\n",
    "对于所有的数据，损失函数值越小，模型越好，学习的目标就是是的模型的损失函数的期望最小，也叫做期望风险最小化，然而由于联合分布$P(X,Y)$未知，无法求得期望风险 $R_{exp}$，，而是通常使用 经验风险 $R_{emp}$来代替 $R_{exp}$，根据大数定律，当样本容量趋于无穷是，$R_{emp}$趋于 $R_{exp}$。\n",
    "$$ R_{emp} = \\frac{1}{N} \\sum_{i=1...N}{L(y_{i}, f(x_{i}))} $$\n",
    "\n",
    "但是，当样本容量很小时，经验风险最小化往往会产生\"过拟合\"问题，过拟合问题是指模型的复杂度高而使得模型将训练集中的数据都记在模型中，这样在训练集上的学习效果往往会非常好，但是在测试集上的预测效果与真实值会有较大的波动。\n",
    "\n",
    "结构风险最小化是为了防止过拟合而提出的策略，结构风险就是经验风险加上正则化项或者惩罚项，\n",
    "$$ R_{srm} = \\frac{1}{N} \\sum_{i=1...N}{L(y_{i}, f(x_{i}))} + \\lambda J(f) $$\n",
    "其中 $J(f)$是正则化项，其是定义在假设空间上的泛函，模型$f$越复杂，$J(f)$就越大。$\\lambda >=0$ 用来权衡经验风险和模型复杂度，也可以理解为 偏差-方差 之间的权衡系数，就是使得结果更偏向于哪一个部分。\n",
    "常见的正则化项有:\n",
    "* L0正则: 是一个NP问题，通常用L1正则代替L0正则\n",
    "* L1正则: $J(f) = ||w||_{1}$，表示为参数向量 $\\vec w$的L1范数\n",
    "* L2正则: $J(f) = ||w||_{2}$，表示为参数向量 $\\vec w$的L2范数\n",
    "\n",
    "* L1正则 + L2 正则: $J(f) = ||w||_{1} + ||w||_{2}$\n",
    "\n",
    "### 2.3 算法\n",
    "当确定模型的假设空间以及学习策略之后，学习目标也就确定了。例如，假设要学习的模型是一个线性模型，学习策略是结构风险最小化，损失函数为平方损失函数，正则化项为L2正则，即:\n",
    "\n",
    "$$ min_{f \\in F} \\frac{1}{N} \\sum_{i=1}^{N}(f(x_{i})-y_{i})^{2} + \\lambda ||w||_{2}$$\n",
    "此时，问题就转化为了数学上的最优化问题，由于这类问题通常没有解析解，采用的方式往往是迭代的优化算法，一步一步的逼近真实解，最常用的优化算法就是梯度下降算法。\n",
    "\n",
    "#### 3.1 梯度下降算法\n",
    "梯度下降算法主要有三个类别，它们的不同在于使用多少样本数量去计算梯度。梯度下降算法有一个非常重要的参数 学习率(Learning rate)，学习率用来控制梯度下降是的步伐大小，如果学习速率设置得非常大，那么训练可能不会收敛，就直接发散了；如果设置的比较小，虽然可以收敛，但是训练时间可能无法接受；如果设置的稍微高一些，训练速度会很快，但是当接近最优点会发生震荡，甚至无法稳定。不同学习速率的选择影响可能非常大。\n",
    "\n",
    "##### 3.1.1 批量梯度下降(Batch gradient descent)\n",
    "每一次的参数更新BGD会使用所有训练样本去计算梯度(平均梯度)，所以使得其训练速度非常慢，但其迭代次数通常较少且较为稳定。\n",
    "\n",
    "参数更新:\n",
    "$$ \\theta_{j}^{'} = \\theta_{j} + \\beta*\\frac{1}{N}\\sum_{i=0}^{N}\\frac{\\alpha J(f(x^{i}, y^{i}))}{\\alpha \\theta_{j}}, for\\  every\\ j $$其中， $\\beta$为学习率。\n",
    "##### 3.1.2 随机梯度下降(Stochastic Gradient Descent)\n",
    "与BGD不同的是SGD每次仅会使用一个样本数据去求梯度，所以其训练速度非常快，但由于数据的不稳定性会导致其收敛速度较低，因为其一次迭代一个样本，迭代方向变化很大，容易引起波动，甚至发散导致不能收敛。\n",
    "\n",
    "参数更新:\n",
    "$$ \\theta_{j}^{'} = \\theta_{j} + \\beta*\\frac{\\alpha J(f(x^{i}, y^{i}))}{\\alpha \\theta_{j}}, for\\  every\\ j $$\n",
    "\n",
    "##### 3.1.3 小批量梯度下降(Mini-Batch Gradient Descent)\n",
    "MBGD是使用实践中最多的算法，因为其结合了BGD和SGD的优点，每次仅选用一小批的样本去求梯度，数量通常是2的次幂(利于并行计算)。\n",
    "\n",
    "参数更新：\n",
    "$$ \\theta_{j}^{'} = \\theta_{j} + \\beta*\\frac{1}{m}\\sum_{i=1}^{m}\\frac{\\alpha J(f(x^{i}, y^{i}))}{\\alpha \\theta_{j}}, 1 \\leq     m \\leq N，for\\  every\\ j $$\n",
    "由于小批量随机梯度下降用的比较多，SGD用的较少，所以一般而言SGD都表示小批量随机梯度下降。\n",
    "#### 3.2 常用的梯度下降算法变种\n",
    "梯度下降的问题:\n",
    "* 很难去选择一个合适的学习率\n",
    "* 所有参数的更新都是使用同一个学习率，但特征的取值空间往往是不同的，那么就会出现问题\n",
    "* 非凸函数容易陷入局部最优点\n",
    "\n",
    "##### 3.2.1 Momentum（动量法）\n",
    "算法:\n",
    "\n",
    "$$ 速度更新： v^{t} =  \\alpha v^{t-1} - \\beta g^{t}, \\alpha \\leq 0.9$$\n",
    "$$ 参数更新：\\theta^{t+1} = \\theta^{t} + v^{t}$$\n",
    "其中，$t$为时刻，$g$为梯度, $\\beta$为学习率，$\\alpha$为超参数.\n",
    "将 $v^{t}$展开:\n",
    "\n",
    "$$ v^{t} = \\alpha^{t}v^{0} - \\beta(\\alpha^{t-1}g^{1} + ... + \\alpha g^{t-1} + g^{t}) $$\n",
    "可以看到 $v$积累了历史的梯度，便于理解只保留两项，$\\alpha^{t}v^{0}$可忽略，设:\n",
    "\n",
    "$$ v^{t} =  -\\beta(\\alpha g^{t-1} + g^{t})$$\n",
    "则有:\n",
    "\n",
    "$$ \\theta^{t} = \\theta^{t-1} - \\beta(\\alpha g^{t-1} + g^{t}) $$\n",
    "由此可知，在更新模型参数时，对于那些当前的梯度方向与上一次梯度方向相同的参数，那么进行加强，即这些方向上更快了；对于那些当前的梯度方向与上一次梯度方向不同的参数，那么进行削减，即这些方向上减慢了。因此可以获得更快的收敛速度与减少振荡。\n",
    "\n",
    "##### 3.2.2 AdaGrad\n",
    "算法:\n",
    "\n",
    "$$ 累计平方梯度: r^{t} = r^{t-1} + g \\odot g $$\n",
    "$$ 更新参数: \\theta^{t} = \\theta^{t-1} + (- \\frac{\\epsilon}{\\delta + \\sqrt{r}} \\odot g) $$\n",
    "其中，$\\epsilon$ 为全局学习率， $\\delta$ 是一个超参数，大约设为 $10^{-7}$由公式可以看出，每个参数所对应的学习率是不同的且能够动态调整，可以把 $\\frac{\\epsilon}{\\delta + \\sqrt{r_{i}}}$ 认为是第$i$个参数的学习率，从这个式子中可以得到这个结论:\n",
    "越陡峭的方向，学习率会越低，平缓的方向，学习率会越高(由$r_{i}$来决定，平缓的方向历史梯度的平方和较小)，从而使得整个的学习曲线变得更加平缓，加快学习速度。\n",
    "\n",
    "缺点：随着迭代的次数越来越多，梯度序列的平方和越来越大(即$r$中的元素越来越大)，由于$r$作为分母，所以会导致学习率逐渐衰减到一个非常小的值。\n",
    "\n",
    "\n",
    "\n",
    "##### 3.2.3 RMSProp\n",
    "RMSProp可用来降低AdaGrad学习率逐渐衰减过快的问题，与ADaGrad相比，RMSProp在计算累计梯度平方时加入了一个衰减系数，主要用来控制保留多少历史信息，与LSTM的遗忘门类似。\n",
    "\n",
    "$$ 累计梯度平方: r^{t} = pr^{t-1} + (1-p)g \\odot g $$\n",
    "其中 $p$为衰减系数。通常设 $p=0.9$.\n",
    "\n",
    "##### 3.2.4 Adam(Adaptive Monment Estimation)\n",
    "Adam 也是一种自适应调整学习率的随机优化算法，可以看作是Monment和RMSProp的结合。\n",
    "\n",
    "算法：\n",
    "\n",
    "$$ 一阶矩(指数加权平均): m^{t} = p_{1}m^{t-1} + (1-p_{1})g $$\n",
    "$$ 二阶矩: r^{t} = p_{2}r^{t-1} + (1-p_{2})g \\odot g$$\n",
    "$$ 修正一阶矩的偏差: \\hat s^{t} = \\frac{s^{t}}{1-p_{1}} $$\n",
    "$$ 修正二阶矩的偏差: \\hat r^{t} = \\frac{r^{t}}{1-p_{2}} $$\n",
    "$$ 参数更新 \\theta = \\theta - \\epsilon \\frac{\\hat s}{\\sqrt{\\hat r} + \\delta}$$\n",
    "常用参数配置: $p_{1} = 0.9, p_{2} = 0.999, \\epsilon = 10^{-8}$\n",
    ">[Adam论文] : https://arxiv.org/abs/1412.6980\n",
    "\n",
    "\n",
    "\n",
    "## 3.参考\n",
    "\n",
    "> 李航, <<统计学习方法>>\n",
    "\n",
    "> 博客: https://blog.csdn.net/BVL10101111/article/details/72614711\n",
    "\n",
    "> 李宏毅: <<什么是深度学习?>>\n",
    "\n",
    "> 优化算法:到底是数学还是代码？: http://www.atyun.com/10927.html\n",
    "\n",
    "> An overview of gradient descent optimization algorithms: http://ruder.io/optimizing-gradient-descent/index.html\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
